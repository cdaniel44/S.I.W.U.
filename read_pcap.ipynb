{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!/usr/local/bin/python3.6\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import hashlib\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "from scapy.all import *\n",
    "from keras.preprocessing.text import hashing_trick\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "\n",
    "packets_testing = rdpcap('./pcap/feeding.pcapng')\n",
    "packets_feeding = rdpcap('./pcap/testing.pcapng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#traitement des paquets ###############################################\n",
    "\n",
    "#feeding tab ##########################################################\n",
    "\n",
    "i = 0\n",
    "feeding_tab = []\n",
    "for y in range(len(packets_feeding)+1):\n",
    "    feeding_tab.append([\"\" for y in range(25)])\n",
    "\n",
    "\n",
    "for packet in packets_feeding:\n",
    "    ###[ Ethernet ]###\n",
    "    feeding_tab[i][0] = packet[0].dst\n",
    "    feeding_tab[i][1] = packet[0].src\n",
    "    feeding_tab[i][2] = packet[0].type\n",
    "    ###[ IP ]###\n",
    "    feeding_tab[i][3] = packet[1].version\n",
    "    feeding_tab[i][4] = packet[1].ihl\n",
    "    feeding_tab[i][5] = packet[1].tos\n",
    "    feeding_tab[i][6] = packet[1].len\n",
    "    feeding_tab[i][7] = packet[1].id\n",
    "    feeding_tab[i][8] = packet[1].frag\n",
    "    feeding_tab[i][9] = packet[1].ttl\n",
    "    feeding_tab[i][10] = packet[1].proto\n",
    "    feeding_tab[i][11] = packet[1].chksum\n",
    "    feeding_tab[i][12] = packet[1].src\n",
    "    feeding_tab[i][13] = packet[1].dst\n",
    "    ###[ TCP ]###\n",
    "    feeding_tab[i][14] = packet[2].sport\n",
    "    feeding_tab[i][15] = packet[2].dport\n",
    "    feeding_tab[i][16] = packet[2].seq\n",
    "    feeding_tab[i][17] = packet[2].ack\n",
    "    feeding_tab[i][18] = packet[2].dataofs\n",
    "    feeding_tab[i][19] = packet[2].reserved\n",
    "    feeding_tab[i][20] = packet[2].window\n",
    "    feeding_tab[i][21] = packet[2].chksum\n",
    "    feeding_tab[i][22] = packet[2].urgptr\n",
    "    if packet[2].options is not None:\n",
    "        feeding_tab[i][23] = packet[2].options\n",
    "    else:\n",
    "        feeding_tab[i][23] = '0'\n",
    "    ###[ Raw ]###\n",
    "    if \"Raw\" in packet:\n",
    "        feeding_tab[i][24] = packet[3].load\n",
    "    else:\n",
    "        feeding_tab[i][24] = '0'\n",
    "\n",
    "    #print(feeding_tab[i][] = [26])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing tab ##########################################################\n",
    "\n",
    "i = 0\n",
    "testing_tab = []\n",
    "for y in range(len(packets_testing)+1):\n",
    "    testing_tab.append([\"\" for y in range(25)])\n",
    "\n",
    "\n",
    "for packet in packets_testing:\n",
    "    #packet.show()\n",
    "    ###[ Ethernet ]###\n",
    "    testing_tab[i][0] = packet[0].dst\n",
    "    testing_tab[i][1] = packet[0].src\n",
    "    testing_tab[i][2] = packet[0].type\n",
    "    ###[ IP ]###\n",
    "    testing_tab[i][3] = packet[1].version\n",
    "    testing_tab[i][4] = packet[1].ihl\n",
    "    testing_tab[i][5] = packet[1].tos\n",
    "    testing_tab[i][6] = packet[1].len\n",
    "    testing_tab[i][7] = packet[1].id\n",
    "    testing_tab[i][8] = packet[1].frag\n",
    "    testing_tab[i][9] = packet[1].ttl\n",
    "    testing_tab[i][10] = packet[1].proto\n",
    "    testing_tab[i][11] = packet[1].chksum\n",
    "    testing_tab[i][12] = packet[1].src\n",
    "    testing_tab[i][13] = packet[1].dst\n",
    "    ###[ TCP ]###\n",
    "    testing_tab[i][14] = packet[2].sport\n",
    "    testing_tab[i][15] = packet[2].dport\n",
    "    testing_tab[i][16] = packet[2].seq\n",
    "    testing_tab[i][17] = packet[2].ack\n",
    "    testing_tab[i][18] = packet[2].dataofs\n",
    "    testing_tab[i][19] = packet[2].reserved\n",
    "    testing_tab[i][20] = packet[2].window\n",
    "    testing_tab[i][21] = packet[2].chksum\n",
    "    testing_tab[i][22] = packet[2].urgptr\n",
    "    if packet[2].options is not None:\n",
    "        testing_tab[i][23] = packet[2].options\n",
    "    else:\n",
    "        testing_tab[i][23] = \"\"\n",
    "    ###[ Raw ]###\n",
    "    if \"Raw\" in packet:\n",
    "        testing_tab[i][24] = packet[3].load\n",
    "    else:\n",
    "        testing_tab[i][24] = \"\"\n",
    "\n",
    "    #print(testing_tab[i][] = [26])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "menace = 0\n",
    "feeding_menace = []\n",
    "for x in range(len(feeding_tab)):\n",
    "    feeding_menace.append(0)\n",
    "\n",
    "for packet in feeding_tab:\n",
    "    if re.search('\\.\\.\\/', str(packet)):\n",
    "        feeding_menace[count] = 1\n",
    "        count += 1\n",
    "    elif re.search('Nikto', str(packet)):\n",
    "        feeding_menace[count] = 1\n",
    "        count += 1\n",
    "    elif re.search('cmd=', str(packet)):\n",
    "        feeding_menace[count] = 1\n",
    "        count += 1\n",
    "    elif re.search('%2F', str(packet)):\n",
    "        feeding_menace[count] = 1\n",
    "        count += 1\n",
    "    elif re.search('passwd', str(packet)):\n",
    "        feeding_menace[count] = 1\n",
    "        count += 1\n",
    "    else:\n",
    "        feeding_menace[count] = 0\n",
    "        count += 1\n",
    "        menace += 1\n",
    "        \n",
    "print(menace)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "menace = 0\n",
    "testing_menace = []\n",
    "for x in range(len(testing_tab)):\n",
    "    testing_menace.append(0)\n",
    "\n",
    "for packet in testing_tab:\n",
    "    if re.search('\\.\\.\\/', str(packet)):\n",
    "        testing_menace[count] = 1\n",
    "        count += 1\n",
    "    elif re.search('Nikto', str(packet)):\n",
    "        testing_menace[count] = 1\n",
    "        count += 1\n",
    "    elif re.search('cmd=', str(packet)):\n",
    "        testing_menace[count] = 1\n",
    "        count += 1\n",
    "    elif re.search('%2F', str(packet)):\n",
    "        testing_menace[count] = 1\n",
    "        count += 1\n",
    "    elif re.search('passwd', str(packet)):\n",
    "        testing_menace[count] = 1\n",
    "        count += 1\n",
    "    else:\n",
    "        testing_menace[count] = 0\n",
    "        count += 1\n",
    "        menace += 1\n",
    "        \n",
    "print(menace)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization des donnees #########################\n",
    "\n",
    "\n",
    "def computeMD5hash(my_string):\n",
    "    m = hashlib.md5()\n",
    "    m.update(my_string.encode('utf-8'))\n",
    "    digest = m.hexdigest()\n",
    "    number = int(digest, 16)\n",
    "    return number\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(feeding_tab)):\n",
    "    for j in range(25):\n",
    "        text = feeding_tab[i][j]\n",
    "        if str(text) == '' or str(0) == str(text):\n",
    "            text = 0\n",
    "        if type(text) == bytes:\n",
    "            if re.match(b'\\x00',text):\n",
    "                text = 0\n",
    "        if type(text) == str:\n",
    "            words = set(text_to_word_sequence(text))\n",
    "            vocab_size = len(words)\n",
    "            tmp = hashing_trick(text, round(vocab_size*1.3), hash_function='md5')\n",
    "            check = ''.join(map(str, tmp))\n",
    "            if type(check) != int:\n",
    "                feeding_tab[i][j] = computeMD5hash(str(check))\n",
    "            else:\n",
    "                feeding_tab[i][j] = computeMD5hash(str(check))\n",
    "\n",
    "\n",
    "\n",
    "        elif type(text) == list or type(text) == bytes:\n",
    "            text = ' '.join(map(str, feeding_tab[i][j]))\n",
    "            words = set(text_to_word_sequence(text))\n",
    "            vocab_size = len(words)\n",
    "            tmp = hashing_trick(text, round(vocab_size*1.3), hash_function='md5')\n",
    "            check = ''.join(map(str, tmp))\n",
    "            if type(check) != int:\n",
    "                feeding_tab[i][j] = computeMD5hash(str(check))\n",
    "            else:\n",
    "                feeding_tab[i][j] = computeMD5hash(str(check))\n",
    "\n",
    "\n",
    "        elif type(text) == int:\n",
    "            feeding_tab[i][j] = text\n",
    "\n",
    "        print(feeding_tab[i][j])\n",
    "        \n",
    "\n",
    "#################################################################\n",
    "#################################################################\n",
    "\n",
    "\n",
    "for i in range(len(testing_tab)):\n",
    "    for j in range(25):\n",
    "        text = testing_tab[i][j]\n",
    "        if str(text) == '' or str(0) == str(text):\n",
    "            text = 0\n",
    "        if type(text) == bytes:\n",
    "            if re.match(b'\\x00',text):\n",
    "                text = 0\n",
    "        if type(text) == str:\n",
    "            words = set(text_to_word_sequence(text))\n",
    "            vocab_size = len(words)\n",
    "            tmp = hashing_trick(text, round(vocab_size*1.3), hash_function='md5')\n",
    "            check = ''.join(map(str, tmp))\n",
    "            if type(check) != int:\n",
    "                testing_tab[i][j] = computeMD5hash(str(check))\n",
    "            else:\n",
    "                testing_tab[i][j] = computeMD5hash(str(check))\n",
    "\n",
    "\n",
    "\n",
    "        elif type(text) == list or type(text) == bytes:\n",
    "            text = ' '.join(map(str, testing_tab[i][j]))\n",
    "            words = set(text_to_word_sequence(text))\n",
    "            vocab_size = len(words)\n",
    "            tmp = hashing_trick(text, round(vocab_size*1.3), hash_function='md5')\n",
    "            check = ''.join(map(str, tmp))\n",
    "            if type(check) != int:\n",
    "                testing_tab[i][j] = computeMD5hash(str(check))\n",
    "            else:\n",
    "                testing_tab[i][j] = computeMD5hash(str(check))\n",
    "\n",
    "\n",
    "        elif type(text) == int:\n",
    "            testing_tab[i][j] = text\n",
    "\n",
    "        print(testing_tab[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape éventuel ###############################################\n",
    "\n",
    "##################################################################\n",
    "\n",
    "nb_classes = 2\n",
    "\n",
    "X_train = np.array(feeding_tab)\n",
    "Y_train = np.array(feeding_menace )\n",
    "X_test = np.array(testing_tab)\n",
    "Y_test = np.array(testing_menace )\n",
    "\n",
    "\n",
    "Y_train = np_utils.to_categorical(Y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(Y_test, nb_classes)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "\n",
    "Y_test = np.array(Y_test)\n",
    "\n",
    "Y_test = np_utils.to_categorical(Y_test, nb_classes)\n",
    "\n",
    "\n",
    "#X_train = np.reshape(X_train, (8208,)).T\n",
    "#X_test =  np.reshape(X_test, (30560,)).T\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "\n",
    "(60000, 784)\n",
    "(60000, 10)\n",
    "(10000, 784)\n",
    "(10000, 10)\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création du modèle\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(2, input_shape=(25,)))\n",
    "model.add(Activation('relu')) # An \"activation\" is just a non-linear function applied to the output\n",
    "                              # of the layer above. Here, with a \"rectified linear unit\",\n",
    "                              # we clamp all values below 0 to 0.\n",
    "                           \n",
    "model.add(Dropout(0.2))   # Dropout helps protect the model from memorizing or \"overfitting\" the training data\n",
    "model.add(Dense(2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('softmax')) # This special \"softmax\" activation among other things,\n",
    "                                 # ensures the output is a valid probaility distribution, that is\n",
    "                                 # that its values are all non-negative and sum to 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compilation du model ###############################################\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training  ###############################################\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=128, epochs=4, verbose=1,\n",
    "         validation_data=(X_test, Y_test))\n",
    "\n",
    "#model.fit(X_train, Y_train, batch_size=128, nb_epoch=4, verbose=1,\n",
    "         #validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # evualtion ###############################################\n",
    "         \n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# résultat ###############################################\n",
    "\n",
    "# The predict_classes function outputs the highest probability class\n",
    "# according to the trained classifier for each input example.\n",
    "predicted_classes = model.predict_classes(X_test)\n",
    "for i in predicted_classes:\n",
    "    print(i)\n",
    "    print(testing_tab[i])\n",
    "# Check which items we got right / wrong\n",
    "correct_indices = np.nonzero(predicted_classes == testing_menace)[0]\n",
    "incorrect_indices = np.nonzero(predicted_classes != testing_menace)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(correct_indices)\n",
    "print(incorrect_indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
